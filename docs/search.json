[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "tutorials/acceptability-ratings.html",
    "href": "tutorials/acceptability-ratings.html",
    "title": "Acceptability Ratings",
    "section": "",
    "text": "See Bross (2019) for a more thorough tutorial on how to analyse acceptability ratings. Below is an example of how a final analysis script might look like."
  },
  {
    "objectID": "tutorials/acceptability-ratings.html#data",
    "href": "tutorials/acceptability-ratings.html#data",
    "title": "Acceptability Ratings",
    "section": "Data",
    "text": "Data\nWe simulate a dataset with subjects and items as random factors.\nWe manipulate word order (SVO vs SOV), within-subject and within-item.\n\n\nCode\nlibrary(tibble)\n\n# Simulate dataset: 10 subjects × 6 items\nset.seed(123)\ndf &lt;- tibble(\n  subject = rep(1:10, each = 6),\n  item = rep(1:3, each = 2, times=10),\n  word_order = rep(c(\"SVO\", \"SOV\"), times=3*10),\n  sentence = rep(c(\n    \"The cat chased the mouse.\",     # SVO\n    \"The cat the mouse chased.\",     # SOV\n    \"She reads books every night.\",  # SVO\n    \"She every night books reads.\",  # SOV\n    \"They are visiting the park.\",   # SVO\n    \"They the park are visiting.\"    # SOV\n  ), times=10),\n  rating = sample(1:5, 60, replace = TRUE)\n)\n\n# Convert to factors for modeling\ndf$word_order &lt;- factor(df$word_order)\ndf$subject &lt;- factor(df$subject)\ndf$item &lt;- factor(df$item)\n\n# Quick check\nhead(df)\n\n\n# A tibble: 6 × 5\n  subject item  word_order sentence                     rating\n  &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;      &lt;chr&gt;                         &lt;int&gt;\n1 1       1     SVO        The cat chased the mouse.         3\n2 1       1     SOV        The cat the mouse chased.         3\n3 1       2     SVO        She reads books every night.      2\n4 1       2     SOV        She every night books reads.      2\n5 1       3     SVO        They are visiting the park.       3\n6 1       3     SOV        They the park are visiting.       5\n\n\n\nDescriptive plot\nThis plot shows rating distributions and means by word order.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# calculate percentage of ratings per word_order\nplot_data &lt;- df %&gt;%\n  group_by(word_order, rating) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(word_order) %&gt;%\n  mutate(percent = n / sum(n) * 100)\n\n# calculate mean ratings per word_order\nmean_data &lt;- df %&gt;%\n  group_by(word_order) %&gt;%\n  summarise(mean_rating = mean(as.numeric(as.character(rating))), .groups = \"drop\")\n\n# colors for 5-point scale\ncolors &lt;- c(\"#b2df8a\", \"#a6d854\", \"#ffffb3\", \"#fdb462\", \"#fb8072\")\n\n# transform rating to ordinal for the plot\nplot_data$rating &lt;- factor(plot_data$rating, levels = 1:5)\n\n# Plot\nggplot(plot_data, aes(x = rating, y = percent, fill = rating)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = sprintf(\"%.1f%%\", percent)), vjust = -0.5, size = 3) +\n  facet_wrap(~word_order, ncol = 1) +\n  geom_vline(\n    data = mean_data,\n    aes(xintercept = mean_rating),\n    linetype = \"dashed\",\n    color = \"black\",\n    linewidth = 0.5\n    ) +\n  geom_text(\n    data = mean_data,\n    aes(x = mean_rating, y = 105, label = sprintf(\"%.2f\", mean_rating)),\n    inherit.aes = FALSE,\n    vjust = 1,\n    hjust = -0.1,\n    size = 3\n    ) +\n  scale_fill_manual(values = colors) +\n  scale_y_continuous(limits = c(0, 115), expand = c(0, 0)) +\n  labs(\n    x = \"Rating\",\n    y = \"Percentage\",\n    fill = \"Rating Scale\"\n    ) +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nPlot by Jennifer Huege."
  },
  {
    "objectID": "tutorials/acceptability-ratings.html#analysis",
    "href": "tutorials/acceptability-ratings.html#analysis",
    "title": "Acceptability Ratings",
    "section": "Analysis",
    "text": "Analysis\nAlthough ratings are ordinal, they are often treated as interval data for scales ≥ 5 points.\nBecause interval data can be analyzed with linear models, and because psycholinguistic designs usually include both subjects and items as random factors, it is common practice to use linear mixed effect models (LMMs) to account for this crossed structure.\nFor an introduction to mixed models, see Winter (2019).\nFor a debate on the specification of the random effects structure of the model, see Barr et al. (2013) and Matuschek et al. (2017).\n\nLinear Mixed Model (LMM)\n\n\nCode\nlibrary(lmerTest)\n\n# Linear Mixed Model (LMM)\nm &lt;- lmer(rating ~ word_order \n          + (1|subject) # adds a random intercept for each participant\n          + (1|item), # adds a random intercept for each item\n          data = df)\nsummary(m)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: rating ~ word_order + (1 | subject) + (1 | item)\n   Data: df\n\nREML criterion at convergence: 208.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.8120 -0.8976 -0.1010  0.6129  2.1572 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 0.0000   0.0000  \n item     (Intercept) 0.4951   0.7036  \n Residual             1.7649   1.3285  \nNumber of obs: 60, groups:  subject, 10; item, 3\n\nFixed effects:\n              Estimate Std. Error      df t value Pr(&gt;|t|)  \n(Intercept)     2.9333     0.4731  2.6487    6.20   0.0121 *\nword_orderSVO  -0.2333     0.3430 56.0000   -0.68   0.4992  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nword_rdrSVO -0.362\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nInterpretation:\nThe fixed effect of word_order tests whether SVO and SOV sentences differ in mean ratings.\n\n(1|subject) captures participant variability.\n(1|item) captures sentence variability.\n\n\nExample Report\n“The model revealed no significant effect of word order. Specifically, SVO sentences were slightly lower than SOV sentences, but the difference was not statistically significant (β = -0.23, SE = 0.34, t(56) = -0.68, p = .50).”\n\n\nPlot of the means predicted by the model.\n\n\nCode\nlibrary(emmeans)\n\n# plot predicted mean acceptability rating\nemm &lt;- emmeans(m, ~ word_order)\ndf$rating &lt;- factor(df$rating, ordered = TRUE, levels = 1:5)\nplot(emm)\n\n\n\n\n\n\n\n\n\n\n\n\nCumulative Link Mixed Model (CLMM)\nA more conservative analysis treating ratings as ordinal.\n\n\nCode\nlibrary(ordinal)\n\n# Cumulative Link Mixed Model (CLMM) --&gt; more conservative\ndf$rating &lt;- factor(df$rating, ordered = TRUE, levels = 1:5)\nm2 &lt;- clmm(rating ~ word_order + (1|subject) + (1|item), data = df)\nsummary(m2)\n\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ word_order + (1 | subject) + (1 | item)\ndata:    df\n\n link  threshold nobs logLik AIC    niter    max.grad cond.H \n logit flexible  60   -93.30 200.60 305(629) 8.87e-05 4.8e+01\n\nRandom effects:\n Groups  Name        Variance  Std.Dev. \n subject (Intercept) 3.792e-14 1.947e-07\n item    (Intercept) 4.851e-01 6.965e-01\nNumber of groups:  subject 10,  item 3 \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\nword_orderSVO  -0.2703     0.4620  -0.585    0.559\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -1.3947     0.5680  -2.456\n2|3  -0.4067     0.5422  -0.750\n3|4   0.6248     0.5452   1.146\n4|5   1.5195     0.5794   2.622"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "r-tutorials",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "This section contains applied R tutorials focused on real-world data problems."
  },
  {
    "objectID": "tutorials/power-analysis.html",
    "href": "tutorials/power-analysis.html",
    "title": "Acceptability Ratings",
    "section": "",
    "text": "See Bross (2019) for a more thorough tutorial on how to analyse acceptability ratings. Below is an example of how a final analysis script might look like."
  },
  {
    "objectID": "tutorials/power-analysis.html#data",
    "href": "tutorials/power-analysis.html#data",
    "title": "Acceptability Ratings",
    "section": "Data",
    "text": "Data\nWe use a simulated dataset with subjects and items as random factors. We manipulate word order (SVO vs. SOV). Word order is manipulated within subject (every subject sees all levels of word order, i.e. both SOV and SVO) and within item (every item has both and SOV and an SVO version).\n\n\nCode\nlibrary(tibble)\n\n# Simulated acceptability judgment dataset with word order manipulation\ndf &lt;- tibble(\n  subject = rep(1:10, each = 6),\n  item = rep(1:3, each = 2, times=10),\n  word_order = rep(c(\"SVO\", \"SOV\"), times=3*10),\n  sentence = rep(c(\n    \"The cat chased the mouse.\",     # SVO\n    \"The cat the mouse chased.\",     # SOV\n    \"She reads books every night.\",  # SVO\n    \"She every night books reads.\",  # SOV\n    \"They are visiting the park.\",   # SVO\n    \"They the park are visiting.\"    # SOV\n  ), times=10),\n  rating = sample(1:7, 60, replace = TRUE)\n)\n\n# Quick check\nhead(df)\n\n\n# A tibble: 6 × 5\n  subject  item word_order sentence                     rating\n    &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;                         &lt;int&gt;\n1       1     1 SVO        The cat chased the mouse.         3\n2       1     1 SOV        The cat the mouse chased.         6\n3       1     2 SVO        She reads books every night.      2\n4       1     2 SOV        She every night books reads.      7\n5       1     3 SVO        They are visiting the park.       2\n6       1     3 SOV        They the park are visiting.       5"
  },
  {
    "objectID": "tutorials/power-analysis.html#analysis",
    "href": "tutorials/power-analysis.html#analysis",
    "title": "Acceptability Ratings",
    "section": "Analysis",
    "text": "Analysis\nAlthough technically it is ordinal data, acceptability ratings are often treated as interval data, especially if the scale is large enough (&gt;= 5). Because designs in psycholinguistics include the concurrent manipulation of subjects and items as random factors, it is common practice to analyse the data with linear mixed effect models.\nFor an introduction to mixed models, see Winter (2019).\nFor a debate on the specification of the random effects structure of the model, see Barr et al. (2013) and Matuschek et al. (2017).\n\nLinear Mixed Model (LMM)\n\n\nCode\nlibrary(lmerTest)\n\n# define factors\ndf$word_order &lt;- factor(df$word_order)\ndf$subject &lt;- factor(df$subject)\ndf$item &lt;- factor(df$item)\n\n# Linear Mixed Model (LMM)\nm &lt;- lmer(rating ~ word_order \n          + (1|subject) # adds a random intercept for each participant\n          + (1|item), # adds a random intercept for each item\n          data = df)\nsummary(m)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: rating ~ word_order + (1 | subject) + (1 | item)\n   Data: df\n\nREML criterion at convergence: 248.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.66752 -0.72202  0.05157  0.65325  1.59875 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n subject  (Intercept) 0.00     0.000   \n item     (Intercept) 0.00     0.000   \n Residual             3.76     1.939   \nNumber of obs: 60, groups:  subject, 10; item, 3\n\nFixed effects:\n              Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)     4.2333     0.3540 58.0000  11.958   &lt;2e-16 ***\nword_orderSVO  -0.3333     0.5007 58.0000  -0.666    0.508    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nword_rdrSVO -0.707\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\nPlot of the means predicted by the model.\n\n\nCode\nlibrary(emmeans)\n\n# plot predicted mean acceptability rating\nemm &lt;- emmeans(m, ~ word_order)\ndf$response &lt;- factor(df$rating, ordered = TRUE, levels = 1:5)\nplot(emm)\n\n\n\n\n\n\n\n\n\n\n\nCumulative Link Mixed Model (CLMM)\nA more conservative analysis can be reported in addition to the that treats the data as ordinal.\n\n\nCode\nlibrary(ordinal)\n\n# Cumulative Link Mixed Model (CLMM) --&gt; more conservative\ndf$rating &lt;- factor(df$rating, ordered = TRUE, levels = 1:5)\nm2 &lt;- clmm(rating ~ word_order + (1|subject) + (1|item), data = df)\nsummary(m2)\n\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rating ~ word_order + (1 | subject) + (1 | item)\ndata:    df\n\n link  threshold nobs logLik AIC    niter    max.grad cond.H \n logit flexible  45   -69.64 153.29 292(155) 7.88e-05 4.1e+01\n\nRandom effects:\n Groups  Name        Variance Std.Dev.\n subject (Intercept) 0        0       \n item    (Intercept) 0        0       \nNumber of groups:  subject 10,  item 3 \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)\nword_orderSVO   0.1258     0.5322   0.236    0.813\n\nThreshold coefficients:\n    Estimate Std. Error z value\n1|2  -1.6274     0.4919  -3.309\n2|3  -0.6293     0.4152  -1.516\n3|4   0.3793     0.4103   0.924\n4|5   0.8619     0.4293   2.008\n(15 observations deleted due to missingness)"
  }
]